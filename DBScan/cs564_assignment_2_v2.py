# -*- coding: utf-8 -*-
"""CS564_Assignment_2_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ILX8UjY2D4Mwp37_9_1i9peuH4orTkS8

## Installing the required libraries . 
[Matplotlib - plotting
Pandas (exporting the csv) 
Scikit-learn to import metrics and packages]
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd 
import seaborn as sns
from sklearn import metrics
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.cluster import DBSCAN

"""## Mounting the CSV files on the Google drive to make it easy for importing"""

from google.colab import drive
drive.mount('/content/drive')

"""## Reading the Country data CSV file """

dc_blobs= pd.read_csv('/content/drive/MyDrive/CS564/cluster_blobs.csv')
dc_circles= pd.read_csv('/content/drive/MyDrive/CS564/cluster_circles.csv')
dc_moons= pd.read_csv('/content/drive/MyDrive/CS564/cluster_moons.csv')

## Displaying the blob data
dc_blobs.head()

## Displaying the circles data
dc_circles.head()

## Displaying the moons data
dc_moons.head()

"""## Data Cleaning (Checking NULL or NAN values)"""

## Checking Null Values for all  the data
print('NULL Value for blob : ',dc_blobs.isnull().sum().sum())
print('NULL Value for Circles : ',dc_circles.isnull().sum().sum())
print('NULL Value for moon : ',dc_moons.isnull().sum().sum())
## Checking NAN Values for al the data
print('NAN Value for blob :',dc_blobs.isnull().sum().sum()) 
print('NAN Value for circles :',dc_circles.isnull().sum().sum()) 
print('NAN Value for moons:',dc_moons.isnull().sum().sum())

"""## Data Scaling for blob data"""

#Scaling the given data
scaler = MinMaxScaler()
dc_blobs_scaled=scaler.fit_transform(dc_blobs)
scaled_dc_blobs=pd.DataFrame(dc_blobs_scaled,columns=dc_blobs.columns)

scaled_dc_blobs

db_blb = DBSCAN(eps=0.35, min_samples=10).fit(scaled_dc_blobs)
core_samples_mask = np.zeros_like(db_blb.labels_, dtype=bool)
#core_samples_mask

core_samples_mask[db_blb.core_sample_indices_] = True
#core_samples_mask

labels = db_blb.labels_
## Defining the number of clusters and since the noise is negligible,thus ignoring it
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)

unique_labels = set(labels)
colors = ['green', 'red','blue']
for k, col in zip(unique_labels, colors):
    if k == -1:
        # Black used for noise.
        col = 'k'
  
    class_member_mask = (labels == k)
  
    xy1 = dc_blobs_scaled[class_member_mask & core_samples_mask]
    plt.plot(xy1[:, 0], xy1[:, 1], 'o', markerfacecolor=col,
             markeredgecolor='k',
             markersize=6)
    
print('number of clusters: %d' % n_clusters_)
plt.title("Clusters for Blob data")
plt.show()
sc = metrics.silhouette_score(dc_blobs_scaled, labels)
print("Silhouette Coefficient:%0.2f"%sc)

"""## Data Scaling for Circles data"""

#Scaling the given data
scaler = MinMaxScaler()
dc_circles_scaled=scaler.fit_transform(dc_circles)
scaled_dc_circles=pd.DataFrame(dc_circles_scaled,columns=dc_circles.columns)

scaled_dc_circles

db_circles = DBSCAN(eps=0.112, min_samples=10).fit(scaled_dc_circles)
core_samples_mask = np.zeros_like(db_circles.labels_, dtype=bool)

core_samples_mask[db_circles.core_sample_indices_] = True

labels = db_circles.labels_
# Number of clusters in labels, ignoring noise if present.
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
unique_labels = set(labels)
colors = ['blue', 'red','yellow']
for k, col in zip(unique_labels, colors):
    if k == -1:
        # Black used for noise.
        col = 'k'
  
    class_member_mask = (labels == k)
  
    xy1 = scaled_dc_circles[class_member_mask & core_samples_mask]
    plt.plot(xy1.X1, xy1.X2, 'o', markerfacecolor=col,
             markeredgecolor='k',
             markersize=6)

print('number of clusters: %d' % n_clusters_)
plt.title("Clusters for Circle data")
plt.show()
sc = metrics.silhouette_score(scaled_dc_circles, labels)
print("Silhouette Coefficient:%0.2f"%sc)

"""## Data Scaling for Moons data"""

#Scaling the given data
scaler = MinMaxScaler()
dc_moon_scaled=scaler.fit_transform(dc_moons)
scaled_dc_moon=pd.DataFrame(dc_moon_scaled,columns=dc_moons.columns)

scaled_dc_moon

db_moon = DBSCAN(eps=0.142, min_samples=10).fit(scaled_dc_moon)
core_samples_mask = np.zeros_like(db_moon.labels_, dtype=bool)

core_samples_mask[db_moon.core_sample_indices_] = True

labels = db_moon.labels_
# Number of clusters in labels, ignoring noise if present.
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
unique_labels = set(labels)
colors = ['blue','green']
for k, col in zip(unique_labels, colors):
    if k == -1:
        # Black used for noise.
        col = 'k'
  
    class_member_mask = (labels == k)
  
    xy1 = scaled_dc_moon[class_member_mask & core_samples_mask]
    plt.plot(xy1.X_1, xy1.X_2, 'o', markerfacecolor=col,
             markeredgecolor='k',
             markersize=6)

print('number of clusters: %d' % n_clusters_)
plt.title("Clusters for Moons data")
plt.show()
sc = metrics.silhouette_score(scaled_dc_moon, labels)
print("Silhouette Coefficient:%0.2f"%sc)

"""## Applying K-means on the blob data"""

## Applying the K-Means
blobs_kmeans= KMeans(n_clusters = 3,random_state = 101)
## Fitting the data
blobs_kmeans.fit(scaled_dc_blobs)
pd.Series(blobs_kmeans.labels_).value_counts()

prediction = blobs_kmeans.labels_
dc_pca_cluster=pd.DataFrame(scaled_dc_blobs)
dc_cluster_data = pd.DataFrame(dc_blobs)
dc_cluster_data['KMeans_Clusters'] = prediction
dc_pca_cluster['KMeans_Clusters']=prediction

sns.scatterplot(dc_pca_cluster['X1'],dc_pca_cluster['X2'],hue='KMeans_Clusters',data=dc_pca_cluster,palette=['green', 'red','blue'], legend='full') 
plt.title("KMeans Clustering for blobs data",fontsize=15)
plt.figure(figsize=(13, 13))
plt.show()

print('Silhouette Score for K-Means :',metrics.silhouette_score(scaled_dc_blobs, blobs_kmeans.labels_))

"""## Applying K-means on the Circle data"""

## Applying the K-Means
circle_kmeans= KMeans(n_clusters = 2,random_state = 101)
## Fitting the data
circle_kmeans.fit(scaled_dc_circles)
pd.Series(circle_kmeans.labels_).value_counts()

prediction = circle_kmeans.labels_
circles_cluster=pd.DataFrame(scaled_dc_circles)
dc_cluster_circles = pd.DataFrame(dc_circles)
dc_cluster_circles['KMeans_Clusters'] = prediction
circles_cluster['KMeans_Clusters']=prediction

sns.scatterplot(circles_cluster['X1'],circles_cluster['X2'],hue='KMeans_Clusters',data=circles_cluster,palette=['blue', 'red'], legend='full') 
plt.title("KMeans Clustering for Circle data",fontsize=15)
plt.figure(figsize=(13, 13))
plt.show()

print('Silhouette Score for K-Means :',metrics.silhouette_score(scaled_dc_circles, circle_kmeans.labels_))

"""## Applying K-means on the moon data"""

## Applying the K-Means
moons_kmeans= KMeans(n_clusters = 2,random_state = 101)
## Fitting the data
moons_kmeans.fit(scaled_dc_blobs)
pd.Series(moons_kmeans.labels_).value_counts()

prediction = moons_kmeans.labels_
moons_cluster=pd.DataFrame(scaled_dc_moon)
scled_cluster_moons = pd.DataFrame(dc_moons)
scled_cluster_moons['KMeans_Clusters'] = prediction
moons_cluster['KMeans_Clusters']=prediction

sns.scatterplot(moons_cluster['X_1'],moons_cluster['X_2'],hue='KMeans_Clusters',data=moons_cluster,palette=['blue','green'], legend='full') 
plt.title("KMeans Clustering for Moons data",fontsize=15)
plt.figure(figsize=(13, 13))
plt.show()

print('Silhouette Score for K-Means :',metrics.silhouette_score(scaled_dc_moon, moons_kmeans.labels_))